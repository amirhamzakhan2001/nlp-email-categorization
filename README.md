# NLP-Based Email Categorization System (Production-Grade)

A full end-to-end **NLP + MLOps** system that automatically categorizes emails using
unsupervised learning, LLM-based labeling, supervised classification, and incremental
updates â€” designed for real-world, long-running inboxes.


## ğŸ“Œ Project Motivation

Email inboxes grow continuously and contain diverse, unstructured text.

Traditional rule-based filters and static classifiers fail because:

- Categories evolve over time
- Manual labeling does not scale
- Models drift as new email types arrive

This project solves these problems by building a **self-adapting email categorization pipeline**
that discovers topics automatically, labels them intelligently, and learns to classify new emails efficiently.



## ğŸ¯ Project Objectives

- Automatically discover email categories (no manual labels)
- Create human-readable cluster labels using LLMs
- Train a supervised model for fast inference
- Support incremental email arrival
- Enable safe periodic retraining
- Maintain production-grade project structure and logging



## ğŸ§  High-Level Approach

1. **Fetch emails** from Gmail using Gmail API  
2. **Clean & normalize text** (subject + body)  
3. **Generate embeddings** using a transformer model  
4. **Reduce dimensionality** using PCA  
5. **Discover clusters** via hierarchical bisecting K-Means  
6. **Generate labels & summaries** using an LLM  
7. **Train a supervised classifier** using AutoML  
8. **Run incremental inference** for new emails  
9. **Periodically retrain** to handle concept drift  



## ğŸ—ï¸ System Architecture
```
Gmail API
â†“
Text Cleaning & Normalization
â†“
Embeddings (Qwen)
â†“
PCA (256-d)
â†“
Hierarchical Clustering
â†“
LLM-based Labeling
â†“
Supervised MLP (AutoML)
â†“
Incremental Inference
â†“
Master Email Dataset
```


## ğŸ“ Complete Project Structure

```
NLP/
â”‚
â”œâ”€â”€ airflow/                                # Airflow DAGs
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ gmail_pipeline_dag.py
â”‚
â”œâ”€â”€ artifacts/                              # ML artifacts (gitignored)
â”‚   â”œâ”€â”€ clustering/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ qwen/
â”‚   â”œâ”€â”€ pca/
â”‚   â””â”€â”€ supervised/
â”‚
â”œâ”€â”€ data/                                   # Local data (gitignored )
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ gmail_cleaned.csv
â”‚   â”‚   â””â”€â”€ gmail_new_mail_buffer.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ gmail_cluster_snapshot.csv
â”‚   â”‚   â””â”€â”€ gmail_master.csv
â”‚   â”‚
â”‚   â””â”€â”€ schema/
â”‚       â””â”€â”€ csv_schema.md
â”‚
â”œâ”€â”€ docker/                                # Docker setup
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ gmail_api_secret/                      # gmail auth credentials ( gitignore )
â”‚   â”œâ”€â”€ gmail_api.json
â”‚   â””â”€â”€ token.json
â”‚
â”œâ”€â”€ hf_models/                             # cache 
â”‚
â”œâ”€â”€ models/                                # model defining
â”‚   â”œâ”€â”€ embedding_models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ qwen.py
â”‚   â”‚
â”‚   â”œâ”€â”€ supervised_models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py
â”‚   â”‚   â””â”€â”€ mlp.py
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”‚
â”œâ”€â”€ outputs/                                # Logs, metrics, visualizations
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ visualizations/
â”‚
â”œâ”€â”€ scripts/                                # linux script
â”‚   â”œâ”€â”€ run_full_pipeline.sh
â”‚   â””â”€â”€ run_incremental_pipeline.sh
â”‚
â”œâ”€â”€ src/                                    # main source file
â”‚   â”‚
â”‚   â”œâ”€â”€ clustering/                         # Unsupervised learning
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cluster_full.py
â”‚   â”‚   â”œâ”€â”€ cluster_tree_builder.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â””â”€â”€ kmeans_recursive.py
â”‚   â”‚
â”‚   â”œâ”€â”€ common/                           	  # Shared utilities
â”‚   â”‚   â”œâ”€â”€ logging.py
â”‚   â”‚   â””â”€â”€ paths.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config/								  # central configeration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ clustering_config.py
â”‚   â”‚   â”œâ”€â”€ embedding_config.py
â”‚   â”‚   â”œâ”€â”€ fetch_config.py
â”‚   â”‚   â”œâ”€â”€ inference_config.py
â”‚   â”‚   â”œâ”€â”€ pipeline_config.py
â”‚   â”‚   â””â”€â”€ supervised_config.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_ops/								# merging csv file
â”‚   â”‚   â””â”€â”€ csv_merge.py
â”‚   â”‚
â”‚   â”œâ”€â”€ embedding/								# Embeddings & PCA
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ csv_io.py
â”‚   â”‚   â”œâ”€â”€ embed_full.py
â”‚   â”‚   â”œâ”€â”€ embed_incremental.py
â”‚   â”‚   â”œâ”€â”€ embedder.py
â”‚   â”‚   â”œâ”€â”€ model_loader.py
â”‚   â”‚   â””â”€â”€ pca_manager.py
â”‚   â”‚
â”‚   â”œâ”€â”€ fetch_gmail/							# Gmail ingestion
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ body_cleaner.py
â”‚   â”‚   â”œâ”€â”€ csv_writer.py
â”‚   â”‚   â”œâ”€â”€ email_parser.py
â”‚   â”‚   â”œâ”€â”€ fetch.py
â”‚   â”‚   â”œâ”€â”€ fetch_and_clean_pipeline.py
â”‚   â”‚   â”œâ”€â”€ fetch_latest_pipeline.py
â”‚   â”‚   â”œâ”€â”€ incremental.py
â”‚   â”‚   â””â”€â”€ subject_cleaner.py
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/							 		# root to leaf cluster path
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ label_path.py
â”‚   â”‚
â”‚   â”œâ”€â”€ inference/								# Incremental inference
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ inf_data_loader.py
â”‚   â”‚   â”œâ”€â”€ infer_supervised.py
â”‚   â”‚   â”œâ”€â”€ inferencer.py
â”‚   â”‚   â”œâ”€â”€ label_path.py
â”‚   â”‚   â””â”€â”€ model_loader.py
â”‚   â”‚
â”‚   â”œâ”€â”€ labeling/							# LLM-based labeling
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ checkpoint_store.py
â”‚   â”‚   â”œâ”€â”€ label_freezer.py
â”‚   â”‚   â”œâ”€â”€ label_generator.py
â”‚   â”‚   â”œâ”€â”€ llm_client.py
â”‚   â”‚   â””â”€â”€ prompt_builder.py
â”‚   â”‚
â”‚   â”œâ”€â”€ outputs/							# outputs function
â”‚   â”‚   â”œâ”€â”€ metrics_writer.py
â”‚   â”‚   â””â”€â”€ visualization_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/								# Orchestration
â”‚   â”‚   â”œâ”€â”€ full_pipeline.py
â”‚   â”‚   â””â”€â”€ incremental_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ supervised/								# Supervised learning
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ automl.py
â”‚   â”‚   â”œâ”€â”€ dataset_builder.py
â”‚   â”‚   â”œâ”€â”€ evaluator.py
â”‚   â”‚   â”œâ”€â”€ sup_data_loader.py
â”‚   â”‚   â”œâ”€â”€ train_supervised_full.py
â”‚   â”‚   â””â”€â”€ trainer.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/								 # deleting saved artifacts
â”‚   â”‚   â””â”€â”€ reset_artifacts.py
â”‚   â”‚
â”‚   â””â”€â”€ visualization/							# visualizing metrices
â”‚       â”œâ”€â”€ cluster_depths.py
â”‚       â”œâ”€â”€ cluster_sizes.py
â”‚       â”œâ”€â”€ embedding_map.py
â”‚       â”œâ”€â”€ generate_visualizations.py
â”‚       â””â”€â”€ sse_metrics.py
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


```

## ğŸ“Š Data Flow

### Full Pipeline (First Run / Retraining)

1. Fetch all emails â†’ `gmail_cleaned.csv`
2. Embed & PCA â†’ `gmail_cluster_snapshot.csv`
3. Hierarchical clustering + LLM labeling
4. Supervised AutoML training
5. Merge â†’ `gmail_master.csv`


### Incremental Pipeline (Regular Updates)

1. Fetch new emails â†’ `gmail_new_mail_buffer.csv`
2. Embed + PCA transform
3. Supervised inference
4. Append to `gmail_master.csv`
5. Delete buffer CSV



## ğŸ” Pipeline Modes

Controlled using environment variable `PIPELINE_MODE`:

| Mode          |       Purpose             |
|---------------|---------------------------|
| `full`        | First-time execution      |
| `incremental` | Regular updates           |
| `retrain`     | Full ML reset and rebuild |

Example:

```
PIPELINE_MODE=retrain python -m src.pipelines.full_pipeline
```



## ğŸ¤– Models Used
	â€¢	Embeddings: Transformer-based (Qwen)
	â€¢	Dimensionality Reduction: PCA (256 dimensions)
	â€¢	Clustering: Hierarchical Bisecting K-Means
	â€¢	Labeling: LLM-based summarization
	â€¢	Classifier: MLP with AutoML architecture search



## ğŸ“ˆ MLOps Principles Applied
	â€¢	Immutable artifacts
	â€¢	Atomic CSV writes
	â€¢	Incremental-safe pipelines
	â€¢	Artifact reset for retraining
	â€¢	Unified logging
	â€¢	AutoML-based model selection



## ğŸ” Environment Setup

	1.	Copy environment file:
	```
    	cp .env.example .env
	```
    2.	Add required keys:
	```
		â€¢	GEMINI_API_KEY
	```


## ğŸ› ï¸ Installation

```
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```


## ğŸ‘¨â€ğŸ“ Academic Context

This project was developed as part of an **MSc in Artificial Intelligence & Machine Learning**
with emphasis on **NLP, clustering, MLOps, and production systems.**

â¸»

### ğŸ‘¤ Author

Amir Hamza Khan
MSc AI & ML
Jamia Millia Islamia

â¸»

### ğŸ“œ License

For academic and research use only.


#### ğŸ¯ Final Status

âœ… README finalized  
âœ… No edits required  
âœ… Matches your full implementation  
âœ… Suitable for GitHub + submission  

If you want next:
- README diagrams (PNG / SVG)
- Architecture flowcharts
- Interview explanation script
- Viva defense Q&A
- 
Just tell me ğŸ‘
